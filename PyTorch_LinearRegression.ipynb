{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5650, 0.7573, 0.3070],\n",
      "        [0.7201, 0.0792, 0.8860],\n",
      "        [0.9115, 0.4237, 0.2501],\n",
      "        [0.3625, 0.9600, 0.2241],\n",
      "        [0.0346, 0.0497, 0.7153]])\n"
     ]
    }
   ],
   "source": [
    "# Verify pytorch is installed correctly\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning \n",
    "### Machine Learning is making the computer learn from studying data and statistics.\n",
    "### Machine Learning is a step into the direction of artificial intelligence (AI).\n",
    "### Machine Learning is a program that analyses data and learns to predict the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with Pytorch \n",
    "### https://pytorch.org/docs/stable/index.html\n",
    "### https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
    "### https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817\n",
    "### https://www.geeksforgeeks.org/linear-regression-using-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n",
    "# In mathematics, a tensor is an algebraic object that describes a (multilinear) relationship between sets of algebraic objects related to a vector space. \n",
    "\n",
    "# Linear Regression is an approach that tries to find a linear relationship \n",
    "# between a dependent variable and an independent variable by minimizing the distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Data Set, y = 2X +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# create dummy data for training\n",
    "x_values = [i for i in range(11)] # zero to 10\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "print(x_train)\n",
    "# reshape with (-1, 1) . We have provided column as 1 but rows as unknown . So we get result new shape as (11, 1).\n",
    "x_train = x_train.reshape(-1, 1) \n",
    "print(x_train)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n"
     ]
    }
   ],
   "source": [
    "print(x_values, y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhUhdXH8e8hYQn7EnYIi2yyixFErCKu4IJKfattXaoWbbW1b62CVqu1tq61tnUrKlWrxVYIShERt4raugBqEvZVCAkBBEKAhGzn/SODb4wzEjNJbjLz+zwPT2buvTP3DMsvl5t7zzF3R0REYlejoAsQEZHapaAXEYlxCnoRkRinoBcRiXEKehGRGJcYdAHhJCcne+/evYMuQ0SkwVi6dOlOd+8Ybl29DPrevXuzZMmSoMsQEWkwzOyzSOt06kZEJMYp6EVEYpyCXkQkxinoRURinIJeRCTG1curbkRE4smLH2/lvldXk72ngG5tk7jh9IGce1T3Gnt/Bb2ISIBe/HgrN6VlUFBcCsDWPQXclJYBUGNhr1M3IiIBuu/V1V+E/CEFxaXc9+rqGtuHgl5EJEBb9xSEXZ4dYXl1KOhFRALy9podJJiFXdetbVKN7Ufn6EVE6tju/UX85uUVpC3bSufWTdm9v5ii0rIv1ic1TuCG0wfW2P4U9CIidcTdeSVzG796KZM9B4r5yYR+XDuhH69kbNNVNyIiDd32vYXc+lImry7PZVj3Njxz+RgGd2sNlF9dU5PBXpmCXkSkFrk7LyzN4s75KzhYUsb0iYO48vg+JCbU3Y9IFfQiIrVky64D3JSWwbvrdjK6T3vuPn8YfTu2rPM6Dvstxcx6mtlbZrbSzJab2XWh5e3N7DUzWxv62i7C688ws9Vmts7Mptf0BxARqW9Ky5yZ727ktD8s5pMte7jz3KE8/8NjAwl5qNoRfQlwvbsvM7NWwFIzew24DHjD3e8OBfh0YFrFF5pZAvAwcCqQBXxkZvPcfUVNfggRkfpibW4+0+aks2zzHsYP7MjvzhtWo5dKVsdhg97dc4Cc0ON8M1sJdAcmA+NDmz0N/JtKQQ+MBta5+wYAM3s+9DoFvYjElOLSMh7793r+/OY6WjRN4MHvjGTyyG5YhOvk69I3OkdvZr2Bo4APgM6hbwK4e46ZdQrzku7AlgrPs4AxEd57KjAVICUl5ZuUJSISqIysPG6Y/SmrtuVz1vCu3H7OEJJbNg26rC9UOejNrCUwB/iZu++t4nepcBt5uA3dfQYwAyA1NTXsNiIi9UlhcSl/eH0Njy/eQHLLpsy4+GhOG9Il6LK+okpBb2aNKQ/559w9LbQ418y6ho7muwLbw7w0C+hZ4XkPIDuagkVE6oMPNnzO9LQMNu7cz0WjezJ94pG0SWocdFlhHTborfzQ/Ulgpbs/UGHVPOBS4O7Q15fCvPwjoL+Z9QG2AhcC3422aBGRoOQXFnPPwlU8+/5mUto35+9XjuG4fslBl/W1qnJEPw64GMgws09Cy26mPOD/aWZXAJuBCwDMrBvwhLtPcvcSM7sWeBVIAGa6+/Ka/hAiInXhrVXbuXluBrl7C7ny+D78/LQBNG9S/29HqspVN+8S/lw7wMlhts8GJlV4vgBYUN0CRUSCtmt/EXf8azkvfpJN/04teeRHx3FUSthbh+ql+v+tSEQkIO7O/PQcbp+3nLyCYq47uT8/PukImiYmBF3aN6KgFxEJqTi7tXPrZiS3bEJm9l5G9GjDcz8cw6AurYMusVoU9CIifHV267a9hWzbW8jkEd144DsjSWgU/I1P1aUJUyIihJ/dCrDks90NOuRBQS8iQmmZ18ns1qAo6EUkrq3els/5j/4n4vqgG5LVBAW9iMSlopIyHnx9DWf9+R227DrAJWN70Szxy5FY07Nbg6IfxopI3Plkyx6mzU5ndW4+k0d247azh9C+RRNGpbSr1dmtQVHQi0jcKCgq5YHXVvPkuxvp1KoZT16ayslHdv5ifW3Pbg2Kgl5E4sJ/1u9k+pwMNu86wHfHpDB94iBaN6ufTchqmoJeRGLa3sJi7lqwilkfbqZXh+bM+uGxjD2iQ9Bl1SkFvYjErNdX5PLLFzPYkX+Qq07oy89OGUBSk4bVvqAmKOhFJOZ8vu8gt/9rBf/6NJtBXVrx+CWpDO/RNuiyAqOgF5GY4e7M+zSb2+ctZ9/BEn5+6gCuPvEImiTG95XkCnoRiQnZewq45cVM3ly1nZE923Lvt4czoHOroMuqFxT0ItKglZU5sz7azF0LVlFa5tx61mAuO653g+9PU5OqMkpwJnAWsN3dh4aW/QM4dLtYW2CPu48M89pNQD5QCpS4e2oN1S0iwsad+5k+J50PNu5iXL8O3HXecFI6NA+6rHqnKkf0TwEPAc8cWuDu3zn02Mx+D+R9zetPcved1S1QRKSyktIynnx3Iw+8toYmiY24d8pwLkjtQfmIa6msKqMEF5tZ73DrQoPD/weYULNliYiEtzJnL9PmpJOelcepgztz57lD6dy6WdBl1WvRnqP/FpDr7msjrHdgkZk58Bd3nxHpjcxsKjAVICUlJcqyRCTWHCwp5eE31/HIv9fTtnljHv7uKCYN66Kj+CqINugvAmZ9zfpx7p5tZp2A18xslbsvDrdh6JvADIDU1FSPsi4RiSFLP9vNtDnprNu+j/OP6s6tZw2mXYsmQZfVYFQ76M0sETgfODrSNu6eHfq63czmAqOBsEEvIgJfntvapU0z+ndqyTvrdtK1dTP++oNjOGlgp6BLbHCiOaI/BVjl7lnhVppZC6CRu+eHHp8G3BHF/kQkxlWe25qTV0hOXiHH90vmsYuPpmVTXRFeHYe9XczMZgH/BQaaWZaZXRFadSGVTtuYWTczWxB62hl418w+BT4EXnb3hTVXuojEmkhzWzfu3K+Qj0JVrrq5KMLyy8IsywYmhR5vAEZEWZ+IxJFYntsapPhuACEi9cKO/INc89yyiOtjYW5rkBT0IhIYdydtWRan/uFtXluRy5nDusbs3NYg6aSXiARi654Cbk7L4O01Ozi6VzvumTKcfp1afumqm1ia2xokBb2I1KmyMufZDz7jnldW4cDtZw/mkrG9aRRqQharc1uDpKAXkTqzfsc+ps9J56NNu/lW/2R+d94werZXE7LapqAXkVpXUlrGjHc28ODra2mW2Ij7vj2cbx+tJmR1RUEvIrVqeXYe0+akk7l1L2cM6cId5w6hUys1IatLCnoRqRWFxaX8+c21PPb2Bto1b8Kj3xvFxGFdgy4rLinoRaTGLdm0i2lz0lm/Yz9TRvXg1rOOpG1zNSELioJeRGrM/oMl3Pfqap7+7ya6tUni6ctHc+KAjkGXFfcU9CJSIxav2cFNaRlk5xVwybG9uOGMQepPU0/oT0FEorLnQBF3vryS2Uuz6NuxBS9cNZbU3u2DLksqUNCLSLW9kpHDrS8tZ/eBIq456Qh+MqE/zRonBF2WVKKgF5FvbHt+Ibe9tJxXMrcxpFtrnr78GIZ0axN0WRKBgl5Eqszdmb00iztfXklBcSk3njGQH36rL40T1B+xPqvK4JGZZrbdzDIrLLvdzLaa2SehX5MivPYMM1ttZuvMbHpNFi4idWvLrgNcMvNDbpidzoDOLXnlum/x4/H9FPINQFWO6J8CHgKeqbT8D+5+f6QXmVkC8DBwKpAFfGRm89x9RTVrFZE6dKiL5NY9BbRJakxBcSmNGxl3TB7C98f0+qIJmdR/h/1W7O6LgV3VeO/RwDp33+DuRcDzwORqvI+I1LFDs1sPTXzKKyimpLSM608b+KVOk9IwRPN/rmvNLD10aqddmPXdgS0VnmeFlolIPXfvwlVfmd1a5vDkuxsDqkiiUd2gfxQ4AhgJ5AC/D7NNuG/5HukNzWyqmS0xsyU7duyoZlkiEq3MrXlk5xWGXafZrQ1TtYLe3XPdvdTdy4DHKT9NU1kW0LPC8x5A9te85wx3T3X31I4ddcu0SF0rLC7lnoWrmPzwe0Q6M6PZrQ1TtYLezCq2oDsPyAyz2UdAfzPrY2ZNgAuBedXZn4jUrg837mLSH9/h0X+vZ8qo7tx57lCSKt34pNmtDddhr7oxs1nAeCDZzLKA24DxZjaS8lMxm4CrQtt2A55w90nuXmJm1wKvAgnATHdfXiufQkSqZd/BEu55ZRV/e/8zerRL4tkrxnB8/2QAmjdJ1OzWGGHuEU+bByY1NdWXLFkSdBkiMe2t1dv5ZVoGOXsLuey43vzitIG0UBOyBsvMlrp7arh1+lMViTO79xfxm/krSPt4K/06tWT21cdxdK9wF85JrFDQi8QJd2dBxjZum5fJngPF/HRCP66Z0I+miWpCFusU9CJxYPveQm55MZNFK3IZ1r0Nz1w+hsHdWgddltQRBb1IDHN3XliSxW9eXkFRSRk3TRzEFcf3IVH9aeKKgl4kRm3+/AA3zU3nvXWfM7pPe+4+fxh9O7YMuiwJgIJeJMaUljlP/WcT97+6moRGxp3nDuW7o1PUnyaOKehFYsja3HxunJPOx5v3cNLAjvz2vGG6m1UU9CKxoKikjMfeXs9Db66jRdMEHvzOSCaP7IaZjuJFQS/S4KVn7eHG2ems2pbP2SO6cdvZg0lu2TTosqQeUdCLNFAFRaU8+PoaHn9nAx1bNeXxS1I5dXDnoMuSekhBL9IAvb/hc6bPSWfT5we4aHRPpk88kjZJjYMuS+opBb1IPXZonN+hxmI/mdCPjK15PPfBZlLaN+fvV47huH7JQZcp9ZyCXqSeOjTO79Ckp617CrgpLQMMrjy+D9efNpCkJmpfIIenoBepp+57dfVXxvk50LFFU245a3AwRUmDpPugReqprRHG9u3cd7COK5GGTkEvUg9tyyukWWL4f566AUq+qcMGvZnNNLPtZpZZYdl9ZrbKzNLNbK6ZtY3w2k1mlmFmn5iZJomIHIa7M+vDzZz6wNuUupNYqW2BxvlJdVTliP4p4IxKy14Dhrr7cGANcNPXvP4kdx8ZafKJiJT77PP9fPfxD7gpLYOh3dvw+s9P5P4LRtC9bRIGdG+bxF3nD9M4P/nGDvvDWHdfbGa9Ky1bVOHp+8C3a7YskfhRWub89b2N3L9oNY0bNeKu84dx4TE9MTN6dWihYJeo1cRVN5cD/4iwzoFFZubAX9x9RqQ3MbOpwFSAlJSUGihLpP5bva28CdmnW/ZwypGduPPcYXRp0yzosiTGRBX0ZvZLoAR4LsIm49w928w6Aa+Z2Sp3Xxxuw9A3gRlQPhw8mrpE6ruikjIefmsdj/x7Ha2aNeZPFx3F2cO7qgmZ1IpqB72ZXQqcBZzs7mGD2d2zQ1+3m9lcYDQQNuhF4sUnW/Zw4+xPWZO7j3NHduNXZw+hfYsmQZclMaxaQW9mZwDTgBPd/UCEbVoAjdw9P/T4NOCOalcq0sAVFJXy+0WrmfneRjq3bsbMy1KZMEhNyKT2HTbozWwWMB5INrMs4DbKr7JpSvnpGID33f1qM+sGPOHuk4DOwNzQ+kTg7+6+sFY+hUg995/1O5k+J4PNuw7wvTEpTJ84iFbN1IRM6kZVrrq5KMziJyNsmw1MCj3eAIyIqjqRBi6voJi7X1nJrA+30LtDc56feizH9u0QdFkSZ9TrRqSWvLYil1tezGBH/kGuOqEvPztlgJqQSSAU9CI1bOe+g9w+bznz03MY1KUVj1+SyvAeYW8eF6kTCnqRGuLuvPRJNr/+13L2HSzh56cO4OoTj6BJhJ41InVFQS9SA7L3FPDLuRm8tXoHR6W05Z4pwxnQuVXQZYkACnqRqJSVOc99uJl7XllFaZnzq7MGc+lxvUlopBufpP5Q0ItU08ad+5k2J50PN+5iXL8O3HXecFI6NA+6LJGvUNCLVEHF2a1d2zTj6F7tWLQilyaJjbh3ynAuSO2h9gVSbynoRQ6j8uzW7LxCstNzGNq9NU9eegydW6sJmdRvuhxA5DDCzW4F2LWvSCEvDYKCXuQwIs1uzckrrONKRKpHp25EIth/sIT7F62OuF6zW6WhUNCLhPHO2h3clJZB1u4Cju+XzJJNuygsKftivWa3SkOioBepIO9AMb9dsIJ/LsmiT3IL/nnVWEb3af+lq266tU3ihtMHasSfNBgKepGQhZnbuPWlTHbtL+JH44/gupP706xxeROyc4/qrmCXBktBL3FvR355E7KXM3IY3LU1f73sGIZ2bxN0WSI1RkEvccvdSVu2lTvmr6CgqJQbTh/I1BP60jhBF6NJbDns32gzm2lm280ss8Ky9mb2mpmtDX1tF+G1Z5jZajNbZ2bTa7JwkWhk7T7ApX/9iOtf+JR+nVqy4Lpvcc1J/RTyEpOq8rf6KeCMSsumA2+4e3/gjdDzLzGzBOBhYCIwGLjIzAZHVa1IlMrKnGf+u4nT/7CYJZt2cfvZg3nhqrH069Qy6NJEak1VRgkuNrPelRZPpnyOLMDTwL8pHxZe0WhgXWikIGb2fOh1K6pdrUgU1u/Yx/Q56Xy0aTff6p/M784bRs/2akImsa+65+g7u3sOgLvnmFmnMNt0B7ZUeJ4FjIn0hmY2FZgKkJKSUs2yRL6quLSMx9/ZwIOvryWpcQL3XzCCKaO6qwmZxI3a/GFsuH9FHmljd58BzABITU2NuJ3IN5G5NY9pc9JZnr2XiUO78OvJQ+jUSv1pJL5UN+hzzaxr6Gi+K7A9zDZZQM8Kz3sA2dXcn8g3Ulhcyp/fXMtjb2+gXfMmPPq9UUwc1jXoskQCUd2gnwdcCtwd+vpSmG0+AvqbWR9gK3Ah8N1q7k+kypZs2sWNc9LZsGM/3z66B7eceSRtmzcJuiyRwBw26M1sFuU/eE02syzgNsoD/p9mdgWwGbggtG034Al3n+TuJWZ2LfAqkADMdPfltfMxRGDfwRLuW7iKZ97/jG5tknjm8tGcMKBj0GWJBK4qV91cFGHVyWG2zQYmVXi+AFhQ7epEqujtNTu4OS2D7LwCLh3bmxtOH0iLprofUAR0Z6w0cHsOFPGb+SuZsyyLIzq24IWrxpLau33QZYnUKwp6aVAqdpFs17wJxWVlHCgq5dqT+nHthH5fNCETkf+noJcGo/Ls1l0HijDg+tMGcO2E/sEWJ1KPqbGHNBj3Llz1ldmtDsz6cEv4F4gIoKCXBmLLrgNkR5jRmh1hpquIlNOpG6nXSkNNyO57dTVG+FurNbtV5Osp6KXeWrc9n2lzMlj62W5OHNCR8QM6cu+rq790+kazW0UOT0Ev9U5xaRkzFm/gj6+vpXnTBB74nxGcd1R5E7J2LZpodqvIN6Sgl3olc2seN8xOZ2XOXs4c3pXbzx5Cx1ZNv1iv2a0i35yCXuqFwuJSHnx9LY+/s4EOLZrwl4uP5vQhXYIuSyQmKOglcB9u3MX0Oels2Lmf76T25OYzj6RNUuOgyxKJGQp6CUx+YTH3LlzN397/jJ7tk3juyjGM65ccdFkiMUdBL4F4a/V2fpmWQc7eQi4f14dfnD6A5k3011GkNuhfltSp3fuL+M38FaR9vJX+nVoy50fHMSqlXdBlicQ0Bb3UCXfn5YwcbntpOXkFxfx0Qj+umdCPpolqQiZS2xT0Uuty9xZyy4uZvLYil+E92vDslWM4smvroMsSiRvVDnozGwj8o8KivsCv3P3BCtuMp3zM4MbQojR3v6O6+5SGxd3555It3PnySopKyrh50iAuH9eHxAS1WBKpS9UOendfDYwEMLMEyufCzg2z6TvuflZ19yMN0+bPDzA9LZ3/rP+cMX3ac8+U4fRObhF0WSJxqaZO3ZwMrHf3z2ro/aSBKi1znvrPJu5/dTUJjYzfnjeUi45JoVEjC7o0kbhVU0F/ITArwrqxZvYpkA38ItKAcDObCkwFSElJqaGypC6tyc3nxtnpfLJlDxMGdeK35w2laxt1lhQJmrmHa/z6Dd7ArAnlIT7E3XMrrWsNlLn7PjObBPzR3Q87Cig1NdWXLFkSVV1Sd4pKynj03+t56K21tGyayO3nDOGcEd0w01G8SF0xs6XunhpuXU0c0U8EllUOeQB331vh8QIze8TMkt19Zw3sVwJScW5rcsumJCYYOXmFnDOiG7edPZgOLZse/k1EpM7URNBfRITTNmbWBch1dzez0ZRPtPq8BvYpAak8t3XHvoMAXHl8H245a3CQpYlIBFFd52ZmzYFTgbQKy642s6tDT78NZIbO0f8JuNCjPVckgbqv0uCPQ17J3BZANSJSFVEd0bv7AaBDpWWPVXj8EPBQNPuQ+mNvYTFbI8xn1dxWkfpLd65IlbyxMpfTHlgccb3mtorUXwp6+Vqf7zvIT2d9zBVPL6FNUmP+95T+JDX+cn8azW0Vqd/U60bCcnfmfZrNr/+1gvzCYn52Sn9+PL4fTRIb0atDC81tFWlAFPTyFTl5BdwyN5M3Vm1nRM+23DtlOAO7tPpivea2ijQsCnr5QlmZ8/xHW7hrwUqKy8q45cwj+cG4PiSofYFIg6agFwA27dzP9LR03t+wi7F9O3D3lGH06qAmZCKxQEEf50pKy5j53kZ+v2gNTRIacff5w/jOMT3VvkAkhijo49iqbXuZNjudT7PyOOXITtx57jC6tGkWdFkiUsMU9HHoYEkpD7+1nkfeWkebpMb8+aKjOGt4Vx3Fi8QoBX2c+XjzbqbNSWdN7j7OHdmNX509hPYtmgRdlojUIgV9nDhQVMLvF61h5nsb6dK6GTMvS2XCoM5BlyUidUBBHwfeW7eT6WnpbNlVwPePTWHaGYNo1axx0GWJSB1R0MewvIJi7lqwkuc/2kLvDs15fuqxHNu3w+FfKCIxRUEfoxYt38YtL2ayc99BrjqxL/97ygCaVepRIyLxQUEfY3buO8jt85YzPz2HQV1a8cSlqQzv0TboskQkQFEFvZltAvKBUqCk8rxCK79e74/AJOAAcJm7L4tmn/L/Ko7069qmGRMGdWJ+Rg4HDpZy/akDuOrEI2iSqAalIvGuJo7oT/qaGbATgf6hX2OAR0NfJUqVR/pl5xXy7Aeb6dWhOS9cNZb+nVsd5h1EJF7U9uHeZOAZL/c+0NbMutbyPuNCpJF+xSVlCnkR+ZJog96BRWa21MymhlnfHdhS4XlWaNlXmNlUM1tiZkt27NgRZVmxL9JIv5y8wjquRETqu2iDfpy7j6L8FM01ZnZCpfXh7qkPOxzc3We4e6q7p3bs2DHKsmJXSWkZj729PuJ6jfQTkcqiHQ6eHfq63czmAqOBioNFs4CeFZ73ALKj2Wc8W5G9lxvnfErm1r0M696Gtbn5FJaUfbFeI/1EJJxqH9GbWQsza3XoMXAakFlps3nAJVbuWCDP3XOqXW2cOlhSyu8Xreach95lW14hj3xvFPOuHcfdU4bTvW0SBnRvm8Rd5w/T5CcR+Ypojug7A3NDHQ8Tgb+7+0IzuxrA3R8DFlB+aeU6yi+v/EF05cafpZ+VNyFbt30f54/qzq1nDqZdqAmZRvqJSFVUO+jdfQMwIszyxyo8duCa6u4jnu0/WML9i1bz1H820a1NEk/94BjGD+wUdFki0gDpzth66J21O7gpLYOs3QVcMrYXN54xiJZN9UclItWj9KhH8g4Uc+fLK3hhaRZ9k1vwz6vGMrpP+6DLEpEGTkFfTyzM3MatL2Wya38RPxp/BNed3F9NyESkRijoA7Y9v5Db5y1nQcY2BndtzV8vO4ah3dsEXZaIxBAFfUDcnbRlW7lj/goKiku54fSBTD2hL40T1IRMRGqWgj4AWbsPcPPcTBav2cHRvdpxz5Th9OvUMuiyRCRGKejrUFmZ87f3P+OehasA+PU5Q7j42F40ahSuU4SISM1Q0NeR9Tv2MW12Oks+2823+ifzu/OG0bN986DLEpE4oKCvZcWlZcxYvIE/vrGWpMYJ3H/BCKaM6k7ojmIRkVqnoK9FmVvzmDYnneXZe5k0rAu3nzOETq2aBV2WiMQZBX0tKCwu5U9vrOUvizfQrnkTHvv+KM4YqnkrIhIMBX2UKs5t7dY2iSmjujM/I4cNO/ZzwdE9uOXMwbRp3jjoMkUkjinoo1B5buvWPQX86c11tG/RhGcuH80JAzRARUSCp7tzohBpbmvTxEYKeRGpNxT0UYg0t3Wb5raKSD2ioK+mBRk5RLrPSXNbRaQ+iWaUYE8ze8vMVprZcjO7Lsw2480sz8w+Cf36VXTlBm/73kKu/ttSfvzcMrq1TaJp4pd/CzW3VUTqm2h+GFsCXO/uy0KzY5ea2WvuvqLSdu+4+1lR7KdecHdeWJrFnfNXcLCkjOkTB3Hl8X2Yn57zpatubjh9oMb7iUi9Es0owRwgJ/Q438xWAt2BykHf4G3ZdYCb0jJ4d91ORvduz91ThtG3Y3kTMs1tFZH6rkYurzSz3sBRwAdhVo81s0+BbOAX7r48wntMBaYCpKSk1ERZUSstc5757ybuXbiaRga/OXco3xudoiZkItKgRB30ZtYSmAP8zN33Vlq9DOjl7vvMbBLwItA/3Pu4+wxgBkBqaqpHW1e01m3P58bZ6SzbvIfxAzvy2/OG0V0/ZBWRBiiqoDezxpSH/HPunlZ5fcXgd/cFZvaImSW7+85o9lubikvL+Mvb6/nTG+to3jSBP3xnBOeOVBMyEWm4qh30Vp58TwIr3f2BCNt0AXLd3c1sNOVX+Xxe3X3WtoysPG6Y/SmrtuVz5vCu/PqcISS3bBp0WSIiUYnmiH4ccDGQYWafhJbdDKQAuPtjwLeBH5lZCVAAXOjugZ+WqaywuJQ/vL6GxxdvILllU/5y8dGcPqRL0GWJiNSIaK66eRf42vMZ7v4Q8FB191EXPtjwOdPTMti4cz8XHtOTmyYdSZskNSETkdgRt03N8guLuWfhKp59fzM92yfx3JVjGNcvOeiyRERqXFwG/VurtvPLuRnk7C3kiuP7cP1pA2jeJC5/K0QkDsRVuu3aX8Rv5q9g7sdb6d+pJXN+dByjUtoFXZaISK2Ki6B3d+an53D7vOXkFRTz05P7c81JR9A0MSHo0kREal3MB33u3kJ+OTeT11fmMrxHG569cgxHdm0ddFkiInUmZoPe3fnHR1v47YKVFJWUcfOkQVw+rg+JCerMLCLxJWaCvuLs1k6tmj8zYIUAAAR4SURBVNI6qTFrt+9jTJ/23DNlOL2TWwRdoohIIGIi6CvPbs3NP0hu/kH+J7UHd58/XE3IRCSuxcR5jEizW99b97lCXkTiXkwEfXaE2a2RlouIxJOYCPpIM1o1u1VEJEaC/obTB5LU+MvXxGt2q4hIuZj4YeyhUX6a3Soi8lUxEfSg2a0iIpHExKkbERGJTEEvIhLjogp6MzvDzFab2Tozmx5mvZnZn0Lr081sVDT7ExGRb67aQW9mCcDDwERgMHCRmQ2utNlEoH/o11Tg0eruT0REqieaI/rRwDp33+DuRcDzwORK20wGnvFy7wNtzaxrFPsUEZFvKJqrbroDWyo8zwLGVGGb7kBO5Tczs6mUH/UD7DOz1dWsKxnYWc3XNlT6zLEv3j4v6DN/U70irYgm6MM1kfFqbFO+0H0GMCOKesp3aLbE3VOjfZ+GRJ859sXb5wV95poUzambLKBnhec9gOxqbCMiIrUomqD/COhvZn3MrAlwITCv0jbzgEtCV98cC+S5+1dO24iISO2p9qkbdy8xs2uBV4EEYKa7Lzezq0PrHwMWAJOAdcAB4AfRl3xYUZ/+aYD0mWNfvH1e0GeuMeYe9pS5iIjECN0ZKyIS4xT0IiIxLmaC/nDtGGKNmfU0s7fMbKWZLTez64Kuqa6YWYKZfWxm84OupS6YWVszm21mq0J/3mODrqm2mdn/hv5eZ5rZLDNrFnRNNc3MZprZdjPLrLCsvZm9ZmZrQ1/b1cS+YiLoq9iOIdaUANe7+5HAscA1cfCZD7kOWBl0EXXoj8BCdx8EjCDGP7uZdQd+CqS6+1DKL/a4MNiqasVTwBmVlk0H3nD3/sAboedRi4mgp2rtGGKKu+e4+7LQ43zK//HHfEN+M+sBnAk8EXQtdcHMWgMnAE8CuHuRu+8Jtqo6kQgkmVki0JwYvP/G3RcDuyotngw8HXr8NHBuTewrVoI+UquFuGBmvYGjgA+CraROPAjcCJQFXUgd6QvsAP4aOl31hJm1CLqo2uTuW4H7gc2Ut0vJc/dFwVZVZzofutco9LVTTbxprAR9lVstxBozawnMAX7m7nuDrqc2mdlZwHZ3Xxp0LXUoERgFPOruRwH7qaH/ztdXofPSk4E+QDeghZl9P9iqGrZYCfq4bLVgZo0pD/nn3D0t6HrqwDjgHDPbRPnpuQlm9mywJdW6LCDL3Q/9b2025cEfy04BNrr7DncvBtKA4wKuqa7kHurwG/q6vSbeNFaCvirtGGKKmRnl521XuvsDQddTF9z9Jnfv4e69Kf8zftPdY/pIz923AVvMbGBo0cnAigBLqgubgWPNrHno7/nJxPgPoCuYB1waenwp8FJNvGlMDAeP1I4h4LJq2zjgYiDDzD4JLbvZ3RcEWJPUjp8Az4UOYjZQN61EAuPuH5jZbGAZ5VeXfUwMtkMws1nAeCDZzLKA24C7gX+a2RWUf8O7oEb2pRYIIiKxLVZO3YiISAQKehGRGKegFxGJcQp6EZEYp6AXEYlxCnoRkRinoBcRiXH/B80ClNmAW39FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Linear Regression with scipy \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "slope, y_intercept, r, p, std_err = stats.linregress(x_values, y_values)\n",
    "print(slope,y_intercept)\n",
    "\n",
    "def myfunc(x):\n",
    "  return slope * x + y_intercept\n",
    "\n",
    "mymodel = list(map(myfunc, x_values))\n",
    "\n",
    "plt.scatter(x_values, y_values)\n",
    "plt.plot(x_values, mymodel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define Linear Regression Model inherits PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module): # Inherit torch neutral network Module\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__() # Call base class constructor \n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize) # Call base class method \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Instantiate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 200\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)\n",
    "\n",
    "##### For GPU #######\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "#initialize \n",
    "#loss (Mean Squared Error)  \n",
    "#optimization (Stochastic Gradient Descent) functions that we’ll use in the training of this model.\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.2394, grad_fn=<MseLossBackward>)\n",
      "epoch 0, loss 50.23941421508789\n",
      "tensor(4.2483, grad_fn=<MseLossBackward>)\n",
      "epoch 1, loss 4.248298168182373\n",
      "tensor(0.4953, grad_fn=<MseLossBackward>)\n",
      "epoch 2, loss 0.49526986479759216\n",
      "tensor(0.1875, grad_fn=<MseLossBackward>)\n",
      "epoch 3, loss 0.18748591840267181\n",
      "tensor(0.1607, grad_fn=<MseLossBackward>)\n",
      "epoch 4, loss 0.1607384979724884\n",
      "tensor(0.1569, grad_fn=<MseLossBackward>)\n",
      "epoch 5, loss 0.1569325029850006\n",
      "tensor(0.1550, grad_fn=<MseLossBackward>)\n",
      "epoch 6, loss 0.15501593053340912\n",
      "tensor(0.1533, grad_fn=<MseLossBackward>)\n",
      "epoch 7, loss 0.15327179431915283\n",
      "tensor(0.1516, grad_fn=<MseLossBackward>)\n",
      "epoch 8, loss 0.15155892074108124\n",
      "tensor(0.1499, grad_fn=<MseLossBackward>)\n",
      "epoch 9, loss 0.14986656606197357\n",
      "tensor(0.1482, grad_fn=<MseLossBackward>)\n",
      "epoch 10, loss 0.14819304645061493\n",
      "tensor(0.1465, grad_fn=<MseLossBackward>)\n",
      "epoch 11, loss 0.14653806388378143\n",
      "tensor(0.1449, grad_fn=<MseLossBackward>)\n",
      "epoch 12, loss 0.14490166306495667\n",
      "tensor(0.1433, grad_fn=<MseLossBackward>)\n",
      "epoch 13, loss 0.14328378438949585\n",
      "tensor(0.1417, grad_fn=<MseLossBackward>)\n",
      "epoch 14, loss 0.14168359339237213\n",
      "tensor(0.1401, grad_fn=<MseLossBackward>)\n",
      "epoch 15, loss 0.1401013731956482\n",
      "tensor(0.1385, grad_fn=<MseLossBackward>)\n",
      "epoch 16, loss 0.13853707909584045\n",
      "tensor(0.1370, grad_fn=<MseLossBackward>)\n",
      "epoch 17, loss 0.136990025639534\n",
      "tensor(0.1355, grad_fn=<MseLossBackward>)\n",
      "epoch 18, loss 0.13546021282672882\n",
      "tensor(0.1339, grad_fn=<MseLossBackward>)\n",
      "epoch 19, loss 0.133947491645813\n",
      "tensor(0.1325, grad_fn=<MseLossBackward>)\n",
      "epoch 20, loss 0.1324518471956253\n",
      "tensor(0.1310, grad_fn=<MseLossBackward>)\n",
      "epoch 21, loss 0.13097278773784637\n",
      "tensor(0.1295, grad_fn=<MseLossBackward>)\n",
      "epoch 22, loss 0.12951022386550903\n",
      "tensor(0.1281, grad_fn=<MseLossBackward>)\n",
      "epoch 23, loss 0.1280638724565506\n",
      "tensor(0.1266, grad_fn=<MseLossBackward>)\n",
      "epoch 24, loss 0.12663370370864868\n",
      "tensor(0.1252, grad_fn=<MseLossBackward>)\n",
      "epoch 25, loss 0.1252199411392212\n",
      "tensor(0.1238, grad_fn=<MseLossBackward>)\n",
      "epoch 26, loss 0.12382148951292038\n",
      "tensor(0.1224, grad_fn=<MseLossBackward>)\n",
      "epoch 27, loss 0.12243879586458206\n",
      "tensor(0.1211, grad_fn=<MseLossBackward>)\n",
      "epoch 28, loss 0.12107159942388535\n",
      "tensor(0.1197, grad_fn=<MseLossBackward>)\n",
      "epoch 29, loss 0.1197194829583168\n",
      "tensor(0.1184, grad_fn=<MseLossBackward>)\n",
      "epoch 30, loss 0.11838248372077942\n",
      "tensor(0.1171, grad_fn=<MseLossBackward>)\n",
      "epoch 31, loss 0.11706061661243439\n",
      "tensor(0.1158, grad_fn=<MseLossBackward>)\n",
      "epoch 32, loss 0.11575355380773544\n",
      "tensor(0.1145, grad_fn=<MseLossBackward>)\n",
      "epoch 33, loss 0.11446087807416916\n",
      "tensor(0.1132, grad_fn=<MseLossBackward>)\n",
      "epoch 34, loss 0.11318271607160568\n",
      "tensor(0.1119, grad_fn=<MseLossBackward>)\n",
      "epoch 35, loss 0.11191876232624054\n",
      "tensor(0.1107, grad_fn=<MseLossBackward>)\n",
      "epoch 36, loss 0.11066918820142746\n",
      "tensor(0.1094, grad_fn=<MseLossBackward>)\n",
      "epoch 37, loss 0.1094331219792366\n",
      "tensor(0.1082, grad_fn=<MseLossBackward>)\n",
      "epoch 38, loss 0.10821118950843811\n",
      "tensor(0.1070, grad_fn=<MseLossBackward>)\n",
      "epoch 39, loss 0.10700274258852005\n",
      "tensor(0.1058, grad_fn=<MseLossBackward>)\n",
      "epoch 40, loss 0.1058080866932869\n",
      "tensor(0.1046, grad_fn=<MseLossBackward>)\n",
      "epoch 41, loss 0.10462640970945358\n",
      "tensor(0.1035, grad_fn=<MseLossBackward>)\n",
      "epoch 42, loss 0.10345807671546936\n",
      "tensor(0.1023, grad_fn=<MseLossBackward>)\n",
      "epoch 43, loss 0.10230287909507751\n",
      "tensor(0.1012, grad_fn=<MseLossBackward>)\n",
      "epoch 44, loss 0.10116034001111984\n",
      "tensor(0.1000, grad_fn=<MseLossBackward>)\n",
      "epoch 45, loss 0.1000308245420456\n",
      "tensor(0.0989, grad_fn=<MseLossBackward>)\n",
      "epoch 46, loss 0.09891363978385925\n",
      "tensor(0.0978, grad_fn=<MseLossBackward>)\n",
      "epoch 47, loss 0.09780919551849365\n",
      "tensor(0.0967, grad_fn=<MseLossBackward>)\n",
      "epoch 48, loss 0.09671695530414581\n",
      "tensor(0.0956, grad_fn=<MseLossBackward>)\n",
      "epoch 49, loss 0.09563703089952469\n",
      "tensor(0.0946, grad_fn=<MseLossBackward>)\n",
      "epoch 50, loss 0.0945688784122467\n",
      "tensor(0.0935, grad_fn=<MseLossBackward>)\n",
      "epoch 51, loss 0.09351294487714767\n",
      "tensor(0.0925, grad_fn=<MseLossBackward>)\n",
      "epoch 52, loss 0.09246862679719925\n",
      "tensor(0.0914, grad_fn=<MseLossBackward>)\n",
      "epoch 53, loss 0.09143614768981934\n",
      "tensor(0.0904, grad_fn=<MseLossBackward>)\n",
      "epoch 54, loss 0.09041494876146317\n",
      "tensor(0.0894, grad_fn=<MseLossBackward>)\n",
      "epoch 55, loss 0.08940552175045013\n",
      "tensor(0.0884, grad_fn=<MseLossBackward>)\n",
      "epoch 56, loss 0.08840710669755936\n",
      "tensor(0.0874, grad_fn=<MseLossBackward>)\n",
      "epoch 57, loss 0.08741963654756546\n",
      "tensor(0.0864, grad_fn=<MseLossBackward>)\n",
      "epoch 58, loss 0.08644355088472366\n",
      "tensor(0.0855, grad_fn=<MseLossBackward>)\n",
      "epoch 59, loss 0.08547835797071457\n",
      "tensor(0.0845, grad_fn=<MseLossBackward>)\n",
      "epoch 60, loss 0.08452380448579788\n",
      "tensor(0.0836, grad_fn=<MseLossBackward>)\n",
      "epoch 61, loss 0.08358003199100494\n",
      "tensor(0.0826, grad_fn=<MseLossBackward>)\n",
      "epoch 62, loss 0.08264651894569397\n",
      "tensor(0.0817, grad_fn=<MseLossBackward>)\n",
      "epoch 63, loss 0.08172371983528137\n",
      "tensor(0.0808, grad_fn=<MseLossBackward>)\n",
      "epoch 64, loss 0.08081118017435074\n",
      "tensor(0.0799, grad_fn=<MseLossBackward>)\n",
      "epoch 65, loss 0.07990872114896774\n",
      "tensor(0.0790, grad_fn=<MseLossBackward>)\n",
      "epoch 66, loss 0.07901635020971298\n",
      "tensor(0.0781, grad_fn=<MseLossBackward>)\n",
      "epoch 67, loss 0.0781339481472969\n",
      "tensor(0.0773, grad_fn=<MseLossBackward>)\n",
      "epoch 68, loss 0.07726147770881653\n",
      "tensor(0.0764, grad_fn=<MseLossBackward>)\n",
      "epoch 69, loss 0.07639865577220917\n",
      "tensor(0.0755, grad_fn=<MseLossBackward>)\n",
      "epoch 70, loss 0.07554555684328079\n",
      "tensor(0.0747, grad_fn=<MseLossBackward>)\n",
      "epoch 71, loss 0.07470183819532394\n",
      "tensor(0.0739, grad_fn=<MseLossBackward>)\n",
      "epoch 72, loss 0.07386767119169235\n",
      "tensor(0.0730, grad_fn=<MseLossBackward>)\n",
      "epoch 73, loss 0.07304287701845169\n",
      "tensor(0.0722, grad_fn=<MseLossBackward>)\n",
      "epoch 74, loss 0.07222720980644226\n",
      "tensor(0.0714, grad_fn=<MseLossBackward>)\n",
      "epoch 75, loss 0.07142070680856705\n",
      "tensor(0.0706, grad_fn=<MseLossBackward>)\n",
      "epoch 76, loss 0.07062307000160217\n",
      "tensor(0.0698, grad_fn=<MseLossBackward>)\n",
      "epoch 77, loss 0.06983456015586853\n",
      "tensor(0.0691, grad_fn=<MseLossBackward>)\n",
      "epoch 78, loss 0.0690547302365303\n",
      "tensor(0.0683, grad_fn=<MseLossBackward>)\n",
      "epoch 79, loss 0.06828353554010391\n",
      "tensor(0.0675, grad_fn=<MseLossBackward>)\n",
      "epoch 80, loss 0.06752102822065353\n",
      "tensor(0.0668, grad_fn=<MseLossBackward>)\n",
      "epoch 81, loss 0.06676711142063141\n",
      "tensor(0.0660, grad_fn=<MseLossBackward>)\n",
      "epoch 82, loss 0.06602150946855545\n",
      "tensor(0.0653, grad_fn=<MseLossBackward>)\n",
      "epoch 83, loss 0.06528424471616745\n",
      "tensor(0.0646, grad_fn=<MseLossBackward>)\n",
      "epoch 84, loss 0.06455527245998383\n",
      "tensor(0.0638, grad_fn=<MseLossBackward>)\n",
      "epoch 85, loss 0.06383436918258667\n",
      "tensor(0.0631, grad_fn=<MseLossBackward>)\n",
      "epoch 86, loss 0.06312157213687897\n",
      "tensor(0.0624, grad_fn=<MseLossBackward>)\n",
      "epoch 87, loss 0.06241661682724953\n",
      "tensor(0.0617, grad_fn=<MseLossBackward>)\n",
      "epoch 88, loss 0.06171970069408417\n",
      "tensor(0.0610, grad_fn=<MseLossBackward>)\n",
      "epoch 89, loss 0.06103034317493439\n",
      "tensor(0.0603, grad_fn=<MseLossBackward>)\n",
      "epoch 90, loss 0.060348913073539734\n",
      "tensor(0.0597, grad_fn=<MseLossBackward>)\n",
      "epoch 91, loss 0.05967508628964424\n",
      "tensor(0.0590, grad_fn=<MseLossBackward>)\n",
      "epoch 92, loss 0.0590086430311203\n",
      "tensor(0.0583, grad_fn=<MseLossBackward>)\n",
      "epoch 93, loss 0.05834965780377388\n",
      "tensor(0.0577, grad_fn=<MseLossBackward>)\n",
      "epoch 94, loss 0.05769810453057289\n",
      "tensor(0.0571, grad_fn=<MseLossBackward>)\n",
      "epoch 95, loss 0.0570538192987442\n",
      "tensor(0.0564, grad_fn=<MseLossBackward>)\n",
      "epoch 96, loss 0.05641676113009453\n",
      "tensor(0.0558, grad_fn=<MseLossBackward>)\n",
      "epoch 97, loss 0.05578676611185074\n",
      "tensor(0.0552, grad_fn=<MseLossBackward>)\n",
      "epoch 98, loss 0.05516376718878746\n",
      "tensor(0.0545, grad_fn=<MseLossBackward>)\n",
      "epoch 99, loss 0.054547715932130814\n",
      "tensor(0.0539, grad_fn=<MseLossBackward>)\n",
      "epoch 100, loss 0.05393854156136513\n",
      "tensor(0.0533, grad_fn=<MseLossBackward>)\n",
      "epoch 101, loss 0.05333632230758667\n",
      "tensor(0.0527, grad_fn=<MseLossBackward>)\n",
      "epoch 102, loss 0.0527406707406044\n",
      "tensor(0.0522, grad_fn=<MseLossBackward>)\n",
      "epoch 103, loss 0.05215172842144966\n",
      "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
      "epoch 104, loss 0.05156934633851051\n",
      "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
      "epoch 105, loss 0.05099349096417427\n",
      "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
      "epoch 106, loss 0.05042405426502228\n",
      "tensor(0.0499, grad_fn=<MseLossBackward>)\n",
      "epoch 107, loss 0.04986095800995827\n",
      "tensor(0.0493, grad_fn=<MseLossBackward>)\n",
      "epoch 108, loss 0.0493043027818203\n",
      "tensor(0.0488, grad_fn=<MseLossBackward>)\n",
      "epoch 109, loss 0.04875361919403076\n",
      "tensor(0.0482, grad_fn=<MseLossBackward>)\n",
      "epoch 110, loss 0.04820931330323219\n",
      "tensor(0.0477, grad_fn=<MseLossBackward>)\n",
      "epoch 111, loss 0.047670844942331314\n",
      "tensor(0.0471, grad_fn=<MseLossBackward>)\n",
      "epoch 112, loss 0.04713845252990723\n",
      "tensor(0.0466, grad_fn=<MseLossBackward>)\n",
      "epoch 113, loss 0.0466122031211853\n",
      "tensor(0.0461, grad_fn=<MseLossBackward>)\n",
      "epoch 114, loss 0.04609164223074913\n",
      "tensor(0.0456, grad_fn=<MseLossBackward>)\n",
      "epoch 115, loss 0.04557694494724274\n",
      "tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "epoch 116, loss 0.04506799578666687\n",
      "tensor(0.0446, grad_fn=<MseLossBackward>)\n",
      "epoch 117, loss 0.044564664363861084\n",
      "tensor(0.0441, grad_fn=<MseLossBackward>)\n",
      "epoch 118, loss 0.0440671406686306\n",
      "tensor(0.0436, grad_fn=<MseLossBackward>)\n",
      "epoch 119, loss 0.043574925512075424\n",
      "tensor(0.0431, grad_fn=<MseLossBackward>)\n",
      "epoch 120, loss 0.043088410049676895\n",
      "tensor(0.0426, grad_fn=<MseLossBackward>)\n",
      "epoch 121, loss 0.042607251554727554\n",
      "tensor(0.0421, grad_fn=<MseLossBackward>)\n",
      "epoch 122, loss 0.04213147237896919\n",
      "tensor(0.0417, grad_fn=<MseLossBackward>)\n",
      "epoch 123, loss 0.041660912334918976\n",
      "tensor(0.0412, grad_fn=<MseLossBackward>)\n",
      "epoch 124, loss 0.04119570180773735\n",
      "tensor(0.0407, grad_fn=<MseLossBackward>)\n",
      "epoch 125, loss 0.04073573276400566\n",
      "tensor(0.0403, grad_fn=<MseLossBackward>)\n",
      "epoch 126, loss 0.04028080776333809\n",
      "tensor(0.0398, grad_fn=<MseLossBackward>)\n",
      "epoch 127, loss 0.03983095660805702\n",
      "tensor(0.0394, grad_fn=<MseLossBackward>)\n",
      "epoch 128, loss 0.03938620910048485\n",
      "tensor(0.0389, grad_fn=<MseLossBackward>)\n",
      "epoch 129, loss 0.03894638642668724\n",
      "tensor(0.0385, grad_fn=<MseLossBackward>)\n",
      "epoch 130, loss 0.03851154074072838\n",
      "tensor(0.0381, grad_fn=<MseLossBackward>)\n",
      "epoch 131, loss 0.03808135911822319\n",
      "tensor(0.0377, grad_fn=<MseLossBackward>)\n",
      "epoch 132, loss 0.03765617311000824\n",
      "tensor(0.0372, grad_fn=<MseLossBackward>)\n",
      "epoch 133, loss 0.03723572939634323\n",
      "tensor(0.0368, grad_fn=<MseLossBackward>)\n",
      "epoch 134, loss 0.036819856613874435\n",
      "tensor(0.0364, grad_fn=<MseLossBackward>)\n",
      "epoch 135, loss 0.036408681422472\n",
      "tensor(0.0360, grad_fn=<MseLossBackward>)\n",
      "epoch 136, loss 0.03600213676691055\n",
      "tensor(0.0356, grad_fn=<MseLossBackward>)\n",
      "epoch 137, loss 0.03560010716319084\n",
      "tensor(0.0352, grad_fn=<MseLossBackward>)\n",
      "epoch 138, loss 0.03520255908370018\n",
      "tensor(0.0348, grad_fn=<MseLossBackward>)\n",
      "epoch 139, loss 0.03480947017669678\n",
      "tensor(0.0344, grad_fn=<MseLossBackward>)\n",
      "epoch 140, loss 0.034420788288116455\n",
      "tensor(0.0340, grad_fn=<MseLossBackward>)\n",
      "epoch 141, loss 0.034036461263895035\n",
      "tensor(0.0337, grad_fn=<MseLossBackward>)\n",
      "epoch 142, loss 0.033656373620033264\n",
      "tensor(0.0333, grad_fn=<MseLossBackward>)\n",
      "epoch 143, loss 0.03328048810362816\n",
      "tensor(0.0329, grad_fn=<MseLossBackward>)\n",
      "epoch 144, loss 0.032908812165260315\n",
      "tensor(0.0325, grad_fn=<MseLossBackward>)\n",
      "epoch 145, loss 0.032541338354349136\n",
      "tensor(0.0322, grad_fn=<MseLossBackward>)\n",
      "epoch 146, loss 0.03217796981334686\n",
      "tensor(0.0318, grad_fn=<MseLossBackward>)\n",
      "epoch 147, loss 0.03181862086057663\n",
      "tensor(0.0315, grad_fn=<MseLossBackward>)\n",
      "epoch 148, loss 0.031463250517845154\n",
      "tensor(0.0311, grad_fn=<MseLossBackward>)\n",
      "epoch 149, loss 0.031111933290958405\n",
      "tensor(0.0308, grad_fn=<MseLossBackward>)\n",
      "epoch 150, loss 0.030764538794755936\n",
      "tensor(0.0304, grad_fn=<MseLossBackward>)\n",
      "epoch 151, loss 0.030420975759625435\n",
      "tensor(0.0301, grad_fn=<MseLossBackward>)\n",
      "epoch 152, loss 0.030081303790211678\n",
      "tensor(0.0297, grad_fn=<MseLossBackward>)\n",
      "epoch 153, loss 0.029745353385806084\n",
      "tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "epoch 154, loss 0.029413260519504547\n",
      "tensor(0.0291, grad_fn=<MseLossBackward>)\n",
      "epoch 155, loss 0.029084766283631325\n",
      "tensor(0.0288, grad_fn=<MseLossBackward>)\n",
      "epoch 156, loss 0.028759993612766266\n",
      "tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "epoch 157, loss 0.028438812121748924\n",
      "tensor(0.0281, grad_fn=<MseLossBackward>)\n",
      "epoch 158, loss 0.028121240437030792\n",
      "tensor(0.0278, grad_fn=<MseLossBackward>)\n",
      "epoch 159, loss 0.027807243168354034\n",
      "tensor(0.0275, grad_fn=<MseLossBackward>)\n",
      "epoch 160, loss 0.02749672532081604\n",
      "tensor(0.0272, grad_fn=<MseLossBackward>)\n",
      "epoch 161, loss 0.02718964032828808\n",
      "tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "epoch 162, loss 0.026886023581027985\n",
      "tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "epoch 163, loss 0.026585804298520088\n",
      "tensor(0.0263, grad_fn=<MseLossBackward>)\n",
      "epoch 164, loss 0.026288973167538643\n",
      "tensor(0.0260, grad_fn=<MseLossBackward>)\n",
      "epoch 165, loss 0.025995366275310516\n",
      "tensor(0.0257, grad_fn=<MseLossBackward>)\n",
      "epoch 166, loss 0.02570509724318981\n",
      "tensor(0.0254, grad_fn=<MseLossBackward>)\n",
      "epoch 167, loss 0.025418031960725784\n",
      "tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "epoch 168, loss 0.02513417787849903\n",
      "tensor(0.0249, grad_fn=<MseLossBackward>)\n",
      "epoch 169, loss 0.024853533133864403\n",
      "tensor(0.0246, grad_fn=<MseLossBackward>)\n",
      "epoch 170, loss 0.02457606792449951\n",
      "tensor(0.0243, grad_fn=<MseLossBackward>)\n",
      "epoch 171, loss 0.02430163510143757\n",
      "tensor(0.0240, grad_fn=<MseLossBackward>)\n",
      "epoch 172, loss 0.024030232802033424\n",
      "tensor(0.0238, grad_fn=<MseLossBackward>)\n",
      "epoch 173, loss 0.023761846125125885\n",
      "tensor(0.0235, grad_fn=<MseLossBackward>)\n",
      "epoch 174, loss 0.02349644899368286\n",
      "tensor(0.0232, grad_fn=<MseLossBackward>)\n",
      "epoch 175, loss 0.023234156891703606\n",
      "tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "epoch 176, loss 0.022974668070673943\n",
      "tensor(0.0227, grad_fn=<MseLossBackward>)\n",
      "epoch 177, loss 0.022718166932463646\n",
      "tensor(0.0225, grad_fn=<MseLossBackward>)\n",
      "epoch 178, loss 0.022464383393526077\n",
      "tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "epoch 179, loss 0.022213557735085487\n",
      "tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "epoch 180, loss 0.021965550258755684\n",
      "tensor(0.0217, grad_fn=<MseLossBackward>)\n",
      "epoch 181, loss 0.02172026038169861\n",
      "tensor(0.0215, grad_fn=<MseLossBackward>)\n",
      "epoch 182, loss 0.021477676928043365\n",
      "tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "epoch 183, loss 0.021237846463918686\n",
      "tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "epoch 184, loss 0.021000701934099197\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "epoch 185, loss 0.020766178146004677\n",
      "tensor(0.0205, grad_fn=<MseLossBackward>)\n",
      "epoch 186, loss 0.020534267649054527\n",
      "tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "epoch 187, loss 0.020304955542087555\n",
      "tensor(0.0201, grad_fn=<MseLossBackward>)\n",
      "epoch 188, loss 0.020078293979167938\n",
      "tensor(0.0199, grad_fn=<MseLossBackward>)\n",
      "epoch 189, loss 0.019854046404361725\n",
      "tensor(0.0196, grad_fn=<MseLossBackward>)\n",
      "epoch 190, loss 0.01963239535689354\n",
      "tensor(0.0194, grad_fn=<MseLossBackward>)\n",
      "epoch 191, loss 0.019413072615861893\n",
      "tensor(0.0192, grad_fn=<MseLossBackward>)\n",
      "epoch 192, loss 0.019196324050426483\n",
      "tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "epoch 193, loss 0.01898195967078209\n",
      "tensor(0.0188, grad_fn=<MseLossBackward>)\n",
      "epoch 194, loss 0.01877003349363804\n",
      "tensor(0.0186, grad_fn=<MseLossBackward>)\n",
      "epoch 195, loss 0.018560366705060005\n",
      "tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "epoch 196, loss 0.01835310272872448\n",
      "tensor(0.0181, grad_fn=<MseLossBackward>)\n",
      "epoch 197, loss 0.01814814656972885\n",
      "tensor(0.0179, grad_fn=<MseLossBackward>)\n",
      "epoch 198, loss 0.017945529893040657\n",
      "tensor(0.0177, grad_fn=<MseLossBackward>)\n",
      "epoch 199, loss 0.017745105549693108\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Converting inputs and labels to Variable\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Linear Regression Model is trained, let’s test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7522009]\n",
      " [ 2.7878861]\n",
      " [ 4.8235717]\n",
      " [ 6.8592567]\n",
      " [ 8.894942 ]\n",
      " [10.930628 ]\n",
      " [12.966312 ]\n",
      " [15.001998 ]\n",
      " [17.037683 ]\n",
      " [19.073368 ]\n",
      " [21.109055 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    if torch.cuda.is_available():\n",
    "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
    "    else:\n",
    "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "    print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
